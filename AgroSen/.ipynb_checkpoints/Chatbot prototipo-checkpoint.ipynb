{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d2c41a9-2477-44c5-a16f-670434e07a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54dde9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cardo\\anaconda3\\Lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\cardo\\anaconda3\\Lib\\site-packages\\tflearn\\optimizers.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "---------------------------------\n",
      "Run id: GN77NG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 30\n",
      "Validation samples: 0\n",
      "--\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 85\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     model\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.tflearn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tflearn\\models\\dnn.py:302\u001b[0m, in \u001b[0;36mDNN.load\u001b[1;34m(self, model_file, weights_only, **optargs)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Load.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03mRestore model weights.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;124;03m             created for the restored variables.\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mrestore(model_file, weights_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptargs)\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39msession\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tflearn\\helpers\\trainer.py:500\u001b[0m, in \u001b[0;36mTrainer.restore\u001b[1;34m(self, model_file, trainable_variable_only, variable_name_map, scope_for_restore, create_new_session, verbose)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trainable_variable_only:\n\u001b[1;32m--> 500\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestorer\u001b[38;5;241m.\u001b[39mrestore(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession, model_file)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\training\\saver.py:1414\u001b[0m, in \u001b[0;36mSaver.restore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m checkpoint_management\u001b[38;5;241m.\u001b[39mcheckpoint_exists_internal(checkpoint_prefix):\n\u001b[1;32m-> 1414\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe passed save_path is not a valid checkpoint: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m   1415\u001b[0m                    checkpoint_prefix)\n\u001b[0;32m   1417\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRestoring parameters from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, checkpoint_prefix)\n",
      "\u001b[1;31mValueError\u001b[0m: The passed save_path is not a valid checkpoint: C:\\Users\\cardo\\Documents\\Samsung\\Chatbot\\model.tflearn",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 87\u001b[0m\n\u001b[0;32m     85\u001b[0m     model\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.tflearn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(training, output, n_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, show_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     88\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.tflearn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Funciones del chatbot\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tflearn\\models\\dnn.py:196\u001b[0m, in \u001b[0;36mDNN.fit\u001b[1;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# Retrieve data preprocesing and augmentation\u001b[39;00m\n\u001b[0;32m    195\u001b[0m daug_dict, dprep_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve_data_preprocessing_and_augmentation()\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mfit(feed_dicts, val_feed_dicts\u001b[38;5;241m=\u001b[39mval_feed_dicts,\n\u001b[0;32m    197\u001b[0m                  n_epoch\u001b[38;5;241m=\u001b[39mn_epoch,\n\u001b[0;32m    198\u001b[0m                  show_metric\u001b[38;5;241m=\u001b[39mshow_metric,\n\u001b[0;32m    199\u001b[0m                  snapshot_step\u001b[38;5;241m=\u001b[39msnapshot_step,\n\u001b[0;32m    200\u001b[0m                  snapshot_epoch\u001b[38;5;241m=\u001b[39msnapshot_epoch,\n\u001b[0;32m    201\u001b[0m                  shuffle_all\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m    202\u001b[0m                  dprep_dict\u001b[38;5;241m=\u001b[39mdprep_dict,\n\u001b[0;32m    203\u001b[0m                  daug_dict\u001b[38;5;241m=\u001b[39mdaug_dict,\n\u001b[0;32m    204\u001b[0m                  excl_trainops\u001b[38;5;241m=\u001b[39mexcl_trainops,\n\u001b[0;32m    205\u001b[0m                  run_id\u001b[38;5;241m=\u001b[39mrun_id,\n\u001b[0;32m    206\u001b[0m                  callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tflearn\\helpers\\trainer.py:341\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, train_op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_ops):\n\u001b[0;32m    339\u001b[0m     caller\u001b[38;5;241m.\u001b[39mon_sub_batch_begin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_state)\n\u001b[1;32m--> 341\u001b[0m     snapshot \u001b[38;5;241m=\u001b[39m train_op\u001b[38;5;241m.\u001b[39m_train(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_state\u001b[38;5;241m.\u001b[39mstep,\n\u001b[0;32m    342\u001b[0m                                (\u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_checkpoint_path) \u001b[38;5;241m|\u001b[39m snapshot_epoch),\n\u001b[0;32m    343\u001b[0m                                snapshot_step,\n\u001b[0;32m    344\u001b[0m                                show_metric)\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;66;03m# Update training state\u001b[39;00m\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_state\u001b[38;5;241m.\u001b[39mupdate(train_op, train_ops_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tflearn\\helpers\\trainer.py:826\u001b[0m, in \u001b[0;36mTrainOp._train\u001b[1;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001b[0m\n\u001b[0;32m    823\u001b[0m epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dflow\u001b[38;5;241m.\u001b[39mdata_status\u001b[38;5;241m.\u001b[39mepoch\n\u001b[0;32m    825\u001b[0m feed_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dflow\u001b[38;5;241m.\u001b[39mnext()\n\u001b[1;32m--> 826\u001b[0m tflearn\u001b[38;5;241m.\u001b[39mis_training(\u001b[38;5;28;01mTrue\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession)\n\u001b[0;32m    827\u001b[0m _, train_summ_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mrun([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msumm_op],\n\u001b[0;32m    828\u001b[0m                                      feed_batch)\n\u001b[0;32m    830\u001b[0m \u001b[38;5;66;03m# Retrieve loss value from summary string\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tflearn\\config.py:95\u001b[0m, in \u001b[0;36mis_training\u001b[1;34m(is_training, session)\u001b[0m\n\u001b[0;32m     93\u001b[0m init_training_mode()\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_training:\n\u001b[1;32m---> 95\u001b[0m     tf\u001b[38;5;241m.\u001b[39mget_collection(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_training_ops\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39meval(session\u001b[38;5;241m=\u001b[39msession)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     tf\u001b[38;5;241m.\u001b[39mget_collection(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_training_ops\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39meval(session\u001b[38;5;241m=\u001b[39msession)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor.py:696\u001b[0m, in \u001b[0;36mTensor.eval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m, feed_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    673\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluates this tensor in a `Session`.\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \n\u001b[0;32m    675\u001b[0m \u001b[38;5;124;03m  Note: If you are not using `compat.v1` libraries, you should not need this,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;124;03m    A numpy array corresponding to the value of this tensor.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 696\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _eval_using_default_session(\u001b[38;5;28mself\u001b[39m, feed_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph, session)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor.py:108\u001b[0m, in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m    104\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m session\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m graph:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use the given session to evaluate tensor: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe tensor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms graph is different from the session\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrun(tensors, feed_dict)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:972\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    969\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 972\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\u001b[38;5;28;01mNone\u001b[39;00m, fetches, feed_dict, options_ptr,\n\u001b[0;32m    973\u001b[0m                      run_metadata_ptr)\n\u001b[0;32m    974\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m    975\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1140\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# Check session.\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[1;32m-> 1140\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempted to use a closed Session.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1142\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe Session graph is empty. Add operations to the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1143\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph before calling run().\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import tensorflow \n",
    "import tflearn\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Inicialización del stemmer de NLTK\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "# Cargar datos y modelo\n",
    "with open('intents.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "try:\n",
    "    \n",
    "    with open(\"data.pickle\", \"rb\") as f:\n",
    "        words, labels, training, output = pickle.load(f)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    \n",
    "    words = []\n",
    "    labels = []\n",
    "    docs_x = []\n",
    "    docs_y = []\n",
    "\n",
    "    for intent in data[0]['intents']:\n",
    "        for pattern in intent['patterns']:\n",
    "            wrds = nltk.word_tokenize(pattern)\n",
    "            words.extend(wrds)\n",
    "            docs_x.append(wrds)\n",
    "            docs_y.append(intent['tag'])\n",
    "\n",
    "        if intent['tag'] not in labels:\n",
    "            labels.append(intent['tag'])\n",
    "\n",
    "    words = [stemmer.stem(w.lower()) for w in words if w != '?']\n",
    "    words = sorted(list(set(words)))\n",
    "\n",
    "    labels = sorted(labels)\n",
    "\n",
    "    training = []\n",
    "    output = []\n",
    "\n",
    "    out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "    for x, doc in enumerate(docs_x):\n",
    "        bag = []\n",
    "\n",
    "        wrds = [stemmer.stem(w.lower()) for w in doc]\n",
    "\n",
    "        for w in words:\n",
    "            if w in wrds:\n",
    "                bag.append(1)\n",
    "            else:\n",
    "                bag.append(0)\n",
    "\n",
    "        output_row = out_empty[:]\n",
    "        output_row[labels.index(docs_y[x])] = 1\n",
    "\n",
    "        training.append(bag)\n",
    "        output.append(output_row)\n",
    "\n",
    "    training = np.array(training)\n",
    "    output = np.array(output)\n",
    "\n",
    "    with open(\"data.pickle\", \"wb\") as f:\n",
    "        pickle.dump((words, labels, training, output), f)\n",
    "\n",
    "tensorflow.compat.v1.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "try:\n",
    "    model.load(\"model.tflearn\")\n",
    "except:\n",
    "    model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "    model.save(\"model.tflearn\")\n",
    "    \n",
    "    \n",
    "# Funciones del chatbot\n",
    "\n",
    "def bag_of_words(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "\n",
    "    return np.array(bag)\n",
    "\n",
    "def chatbot_response(msg):\n",
    "    results = model.predict([bag_of_words(msg, words)])\n",
    "    results_index = np.argmax(results)\n",
    "    tag = labels[results_index]\n",
    "\n",
    "    for tg in data[0]['intents']:\n",
    "        if tg['tag'] == tag:\n",
    "            responses = tg['responses']\n",
    "\n",
    "    return random.choice(responses)\n",
    "\n",
    "####DE AQUI PARA ABAJO ES LO NUEVO####\n",
    "\n",
    "# Configuración de la ventana principal\n",
    "base = Tk()  # Creación de la ventana principal\n",
    "base.title(\"Chatbot\")  # Título de la ventana\n",
    "base.geometry(\"400x500\")  # Tamaño de la ventana\n",
    "\n",
    "# Creación de un área de texto para mostrar el chat\n",
    "ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\")\n",
    "ChatLog.config(foreground=\"black\", font=(\"Verdana\", 12))\n",
    "ChatLog.insert(END, \"SALUDOS BIENVENIDO\" + '\\n\\n')  # Mensaje de bienvenida inicial\n",
    "ChatLog.place(x=6, y=6, height=386, width=370)  # Posicionamiento del área de texto en la ventana\n",
    "\n",
    "# Creación de una barra de desplazamiento para navegar por el historial del chat\n",
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
    "ChatLog['yscrollcommand'] = scrollbar.set\n",
    "scrollbar.place(x=376, y=6, height=386)\n",
    "\n",
    "# Bloquear el área de texto para que no se pueda editar directamente por el usuario\n",
    "ChatLog.config(state=DISABLED)\n",
    "\n",
    "# Creación de un cuadro de entrada de texto para que el usuario escriba sus mensajes\n",
    "EntryBox = Text(base, bd=0, bg=\"white\", width=\"29\", height=\"5\", font=\"Arial\")\n",
    "EntryBox.place(x=6, y=401, height=90, width=265)\n",
    "\n",
    "# Función para enviar un mensaje (se llama cuando se presiona Enter o se hace clic en el botón 'Send')\n",
    "def send(event=None):\n",
    "    msg = EntryBox.get(\"1.0\", 'end-1c').strip()  # Obtener el mensaje escrito por el usuario\n",
    "    EntryBox.delete(\"0.0\", END)  # Limpiar el cuadro de entrada después de enviar el mensaje\n",
    "\n",
    "    if msg != '':\n",
    "        ChatLog.config(state=NORMAL)  # Permitir la escritura en el área de texto\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')  # Mostrar el mensaje del usuario en el chat\n",
    "        ChatLog.config(foreground=\"black\", font=(\"Verdana\", 12))\n",
    "\n",
    "        # Simular la respuesta del chatbot (aquí debería llamarse a una función real de chatbot)\n",
    "        res = chatbot_response(msg)\n",
    "        ChatLog.insert(END, \"ChatBOT: \" + res + '\\n\\n')  # Mostrar la respuesta del chatbot en el chat\n",
    "        ChatLog.config(state=DISABLED)  # Bloquear el área de texto nuevamente\n",
    "        ChatLog.yview(END)  # Desplazar hacia abajo para mostrar la respuesta más reciente\n",
    "\n",
    "# Botón para enviar mensajes\n",
    "SendButton = Button(base, font=(\"Verdana\", 12, 'bold'), text=\"Send\", width=\"9\",\n",
    "                   height=5, bd=0, bg=\"blue\", activebackground=\"gold\",\n",
    "                   fg='#ffffff', command=send)\n",
    "SendButton.place(x=282, y=401, height=90)\n",
    "\n",
    "# Vincular la tecla Enter para enviar mensajes\n",
    "base.bind('<Return>', send)\n",
    "\n",
    "# Iniciar el bucle principal de la interfaz gráfica\n",
    "base.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56713446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3999  | total loss: \u001b[1m\u001b[32m0.00715\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 1000 | loss: 0.00715 - acc: 1.0000 -- iter: 24/30\n",
      "Training Step: 4000  | total loss: \u001b[1m\u001b[32m0.00691\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1000 | loss: 0.00691 - acc: 1.0000 -- iter: 30/30\n",
      "--\n",
      "INFO:tensorflow:C:\\Users\\cardo\\Documents\\Samsung\\Chatbot\\model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import tflearn\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Inicialización del stemmer de NLTK\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "# Cargar datos y modelo\n",
    "with open('intents.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "try:\n",
    "    with open(\"data.pickle\", \"rb\") as f:\n",
    "        words, labels, training, output = pickle.load(f)\n",
    "except (FileNotFoundError, EOFError):\n",
    "    words = []\n",
    "    labels = []\n",
    "    docs_x = []\n",
    "    docs_y = []\n",
    "\n",
    "    for intent in data['intents']:\n",
    "        for pattern in intent['patterns']:\n",
    "            wrds = nltk.word_tokenize(pattern)\n",
    "            words.extend(wrds)\n",
    "            docs_x.append(wrds)\n",
    "            docs_y.append(intent['tag'])\n",
    "\n",
    "        if intent['tag'] not in labels:\n",
    "            labels.append(intent['tag'])\n",
    "\n",
    "    words = [stemmer.stem(w.lower()) for w in words if w != '?']\n",
    "    words = sorted(list(set(words)))\n",
    "\n",
    "    labels = sorted(labels)\n",
    "\n",
    "    training = []\n",
    "    output = []\n",
    "\n",
    "    out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "    for x, doc in enumerate(docs_x):\n",
    "        bag = []\n",
    "\n",
    "        wrds = [stemmer.stem(w.lower()) for w in doc]\n",
    "\n",
    "        for w in words:\n",
    "            if w in wrds:\n",
    "                bag.append(1)\n",
    "            else:\n",
    "                bag.append(0)\n",
    "\n",
    "        output_row = out_empty[:]\n",
    "        output_row[labels.index(docs_y[x])] = 1\n",
    "\n",
    "        training.append(bag)\n",
    "        output.append(output_row)\n",
    "\n",
    "    training = np.array(training)\n",
    "    output = np.array(output)\n",
    "\n",
    "    with open(\"data.pickle\", \"wb\") as f:\n",
    "        pickle.dump((words, labels, training, output), f)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "# Verificar si el archivo de punto de control existe\n",
    "checkpoint_path = \"model.tflearn\"\n",
    "if os.path.isfile(checkpoint_path + \".index\"):\n",
    "    model.load(checkpoint_path)\n",
    "else:\n",
    "    model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "    model.save(checkpoint_path)\n",
    "\n",
    "# Funciones del chatbot\n",
    "\n",
    "def bag_of_words(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "\n",
    "    return np.array(bag)\n",
    "\n",
    "def chatbot_response(msg):\n",
    "    results = model.predict([bag_of_words(msg, words)])\n",
    "    results_index = np.argmax(results)\n",
    "    tag = labels[results_index]\n",
    "\n",
    "    for tg in data['intents']:\n",
    "        if tg['tag'] == tag:\n",
    "            responses = tg['responses']\n",
    "\n",
    "    return random.choice(responses)\n",
    "\n",
    "# Configuración de la ventana principal\n",
    "base = Tk()  # Creación de la ventana principal\n",
    "base.title(\"Chatbot\")  # Título de la ventana\n",
    "base.geometry(\"400x500\")  # Tamaño de la ventana\n",
    "\n",
    "# Creación de un área de texto para mostrar el chat\n",
    "ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\")\n",
    "ChatLog.config(foreground=\"black\", font=(\"Verdana\", 12))\n",
    "ChatLog.insert(END, \"SALUDOS BIENVENIDO\" + '\\n\\n')  # Mensaje de bienvenida inicial\n",
    "ChatLog.place(x=6, y=6, height=386, width=370)  # Posicionamiento del área de texto en la ventana\n",
    "\n",
    "# Creación de una barra de desplazamiento para navegar por el historial del chat\n",
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
    "ChatLog['yscrollcommand'] = scrollbar.set\n",
    "scrollbar.place(x=376, y=6, height=386)\n",
    "\n",
    "# Bloquear el área de texto para que no se pueda editar directamente por el usuario\n",
    "ChatLog.config(state=DISABLED)\n",
    "\n",
    "# Creación de un cuadro de entrada de texto para que el usuario escriba sus mensajes\n",
    "EntryBox = Text(base, bd=0, bg=\"white\", width=\"29\", height=\"5\", font=\"Arial\")\n",
    "EntryBox.place(x=6, y=401, height=90, width=265)\n",
    "\n",
    "# Función para enviar un mensaje (se llama cuando se presiona Enter o se hace clic en el botón 'Send')\n",
    "def send(event=None):\n",
    "    msg = EntryBox.get(\"1.0\", 'end-1c').strip()  # Obtener el mensaje escrito por el usuario\n",
    "    EntryBox.delete(\"0.0\", END)  # Limpiar el cuadro de entrada después de enviar el mensaje\n",
    "\n",
    "    if msg != '':\n",
    "        ChatLog.config(state=NORMAL)  # Permitir la escritura en el área de texto\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')  # Mostrar el mensaje del usuario en el chat\n",
    "        ChatLog.config(foreground=\"black\", font=(\"Verdana\", 12))\n",
    "\n",
    "        # Simular la respuesta del chatbot (aquí debería llamarse a una función real de chatbot)\n",
    "        res = chatbot_response(msg)\n",
    "        ChatLog.insert(END, \"ChatBOT: \" + res + '\\n\\n')  # Mostrar la respuesta del chatbot en el chat\n",
    "        ChatLog.config(state=DISABLED)  # Bloquear el área de texto nuevamente\n",
    "        ChatLog.yview(END)  # Desplazar hacia abajo para mostrar la respuesta más reciente\n",
    "\n",
    "# Botón para enviar mensajes\n",
    "SendButton = Button(base, font=(\"Verdana\", 12, 'bold'), text=\"Send\", width=\"9\",\n",
    "                   height=5, bd=0, bg=\"blue\", activebackground=\"gold\",\n",
    "                   fg='#ffffff', command=send)\n",
    "SendButton.place(x=282, y=401, height=90)\n",
    "\n",
    "# Vincular la tecla Enter para enviar mensajes\n",
    "base.bind('<Return>', send)\n",
    "\n",
    "# Iniciar el bucle principal de la interfaz gráfica\n",
    "base.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8608c88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\cardo\\Documents\\Samsung\\Chatbot\\model.tflearn\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import tflearn\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Inicialización del stemmer de NLTK\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "# Cargar datos y modelo\n",
    "with open('intents.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "try:\n",
    "    with open(\"data.pickle\", \"rb\") as f:\n",
    "        words, labels, training, output = pickle.load(f)\n",
    "except (FileNotFoundError, EOFError):\n",
    "    words = []\n",
    "    labels = []\n",
    "    docs_x = []\n",
    "    docs_y = []\n",
    "\n",
    "    for intent in data['intents']:\n",
    "        for pattern in intent['patterns']:\n",
    "            wrds = nltk.word_tokenize(pattern)\n",
    "            words.extend(wrds)\n",
    "            docs_x.append(wrds)\n",
    "            docs_y.append(intent['tag'])\n",
    "\n",
    "        if intent['tag'] not in labels:\n",
    "            labels.append(intent['tag'])\n",
    "\n",
    "    words = [stemmer.stem(w.lower()) for w in words if w != '?']\n",
    "    words = sorted(list(set(words)))\n",
    "\n",
    "    labels = sorted(labels)\n",
    "\n",
    "    training = []\n",
    "    output = []\n",
    "\n",
    "    out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "    for x, doc in enumerate(docs_x):\n",
    "        bag = []\n",
    "\n",
    "        wrds = [stemmer.stem(w.lower()) for w in doc]\n",
    "\n",
    "        for w in words:\n",
    "            if w in wrds:\n",
    "                bag.append(1)\n",
    "            else:\n",
    "                bag.append(0)\n",
    "\n",
    "        output_row = out_empty[:]\n",
    "        output_row[labels.index(docs_y[x])] = 1\n",
    "\n",
    "        training.append(bag)\n",
    "        output.append(output_row)\n",
    "\n",
    "    training = np.array(training)\n",
    "    output = np.array(output)\n",
    "\n",
    "    with open(\"data.pickle\", \"wb\") as f:\n",
    "        pickle.dump((words, labels, training, output), f)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "# Verificar si el archivo de punto de control existe\n",
    "checkpoint_path = \"model.tflearn\"\n",
    "if os.path.isfile(checkpoint_path + \".index\"):\n",
    "    model.load(checkpoint_path)\n",
    "else:\n",
    "    model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "    model.save(checkpoint_path)\n",
    "\n",
    "# Funciones del chatbot\n",
    "\n",
    "def bag_of_words(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "\n",
    "    return np.array(bag)\n",
    "\n",
    "def chatbot_response(msg):\n",
    "    results = model.predict([bag_of_words(msg, words)])\n",
    "    results_index = np.argmax(results)\n",
    "    tag = labels[results_index]\n",
    "\n",
    "    for tg in data['intents']:\n",
    "        if tg['tag'] == tag:\n",
    "            responses = tg['responses']\n",
    "\n",
    "    return random.choice(responses)\n",
    "\n",
    "# Configuración de la ventana principal\n",
    "base = Tk()  # Creación de la ventana principal\n",
    "base.title(\"Chatbot\")  # Título de la ventana\n",
    "base.geometry(\"400x500\")  # Tamaño de la ventana\n",
    "\n",
    "# Creación de un área de texto para mostrar el chat\n",
    "ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\")\n",
    "ChatLog.config(foreground=\"black\", font=(\"Verdana\", 12))\n",
    "ChatLog.insert(END, \"SALUDOS BIENVENIDO\" + '\\n\\n')  # Mensaje de bienvenida inicial\n",
    "ChatLog.place(x=6, y=6, height=386, width=370)  # Posicionamiento del área de texto en la ventana\n",
    "\n",
    "# Creación de una barra de desplazamiento para navegar por el historial del chat\n",
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
    "ChatLog['yscrollcommand'] = scrollbar.set\n",
    "scrollbar.place(x=376, y=6, height=386)\n",
    "\n",
    "# Bloquear el área de texto para que no se pueda editar directamente por el usuario\n",
    "ChatLog.config(state=DISABLED)\n",
    "\n",
    "# Creación de un cuadro de entrada de texto para que el usuario escriba sus mensajes\n",
    "EntryBox = Text(base, bd=0, bg=\"white\", width=\"29\", height=\"5\", font=\"Arial\")\n",
    "EntryBox.place(x=6, y=401, height=90, width=265)\n",
    "\n",
    "# Función para enviar un mensaje (se llama cuando se presiona Enter o se hace clic en el botón 'Send')\n",
    "def send(event=None):\n",
    "    msg = EntryBox.get(\"1.0\", 'end-1c').strip()  # Obtener el mensaje escrito por el usuario\n",
    "    EntryBox.delete(\"0.0\", END)  # Limpiar el cuadro de entrada después de enviar el mensaje\n",
    "\n",
    "    if msg != '':\n",
    "        ChatLog.config(state=NORMAL)  # Permitir la escritura en el área de texto\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')  # Mostrar el mensaje del usuario en el chat\n",
    "        ChatLog.config(foreground=\"black\", font=(\"Verdana\", 12))\n",
    "\n",
    "        # Simular la respuesta del chatbot (aquí debería llamarse a una función real de chatbot)\n",
    "        res = chatbot_response(msg)\n",
    "        ChatLog.insert(END, \"ChatBOT: \" + res + '\\n\\n')  # Mostrar la respuesta del chatbot en el chat\n",
    "        ChatLog.config(state=DISABLED)  # Bloquear el área de texto nuevamente\n",
    "        ChatLog.yview(END)  # Desplazar hacia abajo para mostrar la respuesta más reciente\n",
    "\n",
    "# Botón para enviar mensajes\n",
    "SendButton = Button(base, font=(\"Verdana\", 12, 'bold'), text=\"Send\", width=\"9\",\n",
    "                   height=5, bd=0, bg=\"blue\", activebackground=\"gold\",\n",
    "                   fg='#ffffff', command=send)\n",
    "SendButton.place(x=282, y=401, height=90)\n",
    "\n",
    "# Vincular la tecla Enter para enviar mensajes\n",
    "base.bind('<Return>', send)\n",
    "\n",
    "# Iniciar el bucle principal de la interfaz gráfica\n",
    "base.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f066f7-f6e0-45da-bdb0-de5ea30c6306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
