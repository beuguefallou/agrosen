{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0049ba7b-d554-430f-a8ef-e89ecd0d73f4",
   "metadata": {},
   "source": [
    "# Chatbot de Agricultura Sostenible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c6c81-f673-48f0-b225-562c5120d05e",
   "metadata": {},
   "source": [
    "Se realizó como proyecto una software de agricultura sostenible que funciona con un chatbot. Se realizó en el idioma español con la biblioteca SpaCy para utilizar un lematizador para los tokens de una oración y en base a esto el modelo puede clasificar en un archivo intents.JSON las posibles respuestas al usuario. La idea del proyecto es una funcionalidad en servidor con FLASK en la que por un API se va a mandar al dominio que tendrá la interfaz del chatbot para resolver problemas con respecto a plagas, hay un problema en el tokenizador en el chatbot de servidor donde solo funciona si se llena la oración en el mismo formato de caracteres que en el archivo JSON. Por medio del archivo Jupyter se tiene una interfaz local en la que el chatbot tiene corregido ese problema y el tokenizador funciona sin inconvenientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a0b64-ba46-4c7f-891a-2328a3218084",
   "metadata": {},
   "source": [
    "El chatbot funciona consultando cuando la planta tiene una de las siguientes plagas: Mancha bacteriana, Sarampion negro, pudrición negra, tizón temprano, tizón tardío, quemadura de la hoja, óxido, costra, mancha, también hay opción de desconocido y sin plaga. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8608c88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6999  | total loss: \u001b[1m\u001b[32m0.00069\u001b[0m\u001b[0m | time: 0.013s\n",
      "| Adam | epoch: 1000 | loss: 0.00069 - acc: 1.0000 -- iter: 48/54\n",
      "Training Step: 7000  | total loss: \u001b[1m\u001b[32m0.00066\u001b[0m\u001b[0m | time: 0.015s\n",
      "| Adam | epoch: 1000 | loss: 0.00066 - acc: 1.0000 -- iter: 54/54\n",
      "--\n",
      "INFO:tensorflow:C:\\Users\\cardo\\Documents\\Samsung\\Chatbot prototipo\\model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import nltk\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import tflearn\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import spacy\n",
    "import re\n",
    "#Se realizan las importaciones incluyendo un comportamiento de v1 de tensorflow por problemas de compatibilidad con tflearn \n",
    "\n",
    "nlp = spacy.load('es_core_news_sm')#SpaCy carga la biblioteca para lemas en español\n",
    "\n",
    "\n",
    "with open('intents.json', encoding='utf-8') as file:#se cargan los datos con encoding utf-8 para caracteres especiales\n",
    "    data = json.load(file)\n",
    "\n",
    "def lemmatize_sentence(sentence):#función de lematización, se convierte la oración en minúscula para indiferencia de mayus \n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('[^a-zA-ZáéíóúÁÉÍÓÚñÑüÜ]', ' ', sentence)#exluyendo letras de a-z y las comas, todos los caracteres se transforman en espacios\n",
    "    doc = nlp(sentence)\n",
    "    lemmas = [token.lemma_ for token in doc]#se aplica el lema por cada token\n",
    "    print(f\"Lemmatized '{sentence}' to {lemmas}\")  \n",
    "    return lemmas\n",
    "\n",
    "\n",
    "if os.path.exists(\"data.pickle\"):\n",
    "    os.remove(\"data.pickle\")\n",
    "if os.path.exists(\"model.tflearn.index\"):\n",
    "    os.remove(\"model.tflearn.index\")\n",
    "if os.path.exists(\"model.tflearn.meta\"):\n",
    "    os.remove(\"model.tflearn.meta\")\n",
    "if os.path.exists(\"model.tflearn.data-00000-of-00001\"):\n",
    "    os.remove(\"model.tflearn.data-00000-of-00001\")#Cada vez que se compile en chatbot se eliminan archivos previos para evitar duplicados\n",
    "\n",
    "print(\"Archivos antiguos eliminados, procesando datos y entrenando el modelo desde cero\")\n",
    "\n",
    "words = []\n",
    "labels = []\n",
    "docs_x = []\n",
    "docs_y = []\n",
    "\n",
    "for intent in data['intents']:#Se tokeniza cada palabra y se guardan las palabras tokenizadas y sus tag en los arrays de información guardada\n",
    "    for pattern in intent['patterns']:\n",
    "        wrds = nltk.word_tokenize(pattern)\n",
    "        docs_x.append(wrds)\n",
    "        docs_y.append(intent['tag'])\n",
    "\n",
    "        \n",
    "        words.extend(lemmatize_sentence(pattern))\n",
    "\n",
    "    if intent['tag'] not in labels:#Si no hay tag se agrega\n",
    "        labels.append(intent['tag'])\n",
    "\n",
    "words = sorted(list(set(words)))\n",
    "labels = sorted(labels)\n",
    "\n",
    "training = []\n",
    "output = []\n",
    "\n",
    "out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "for x, doc in enumerate(docs_x):\n",
    "    bag = []\n",
    "    wrds = lemmatize_sentence(' '.join(doc))\n",
    "\n",
    "    for w in words:\n",
    "        if w in wrds:#se convierten las palabras que estén relacionadas en la bolsa de palabras con un 1 y las demás con 0\n",
    "            bag.append(1)\n",
    "        else:\n",
    "            bag.append(0)\n",
    "\n",
    "    output_row = out_empty[:]\n",
    "    output_row[labels.index(docs_y[x])] = 1\n",
    "\n",
    "    training.append(bag)\n",
    "    output.append(output_row)\n",
    "\n",
    "training = np.array(training)\n",
    "output = np.array(output)\n",
    "\n",
    "with open(\"data.pickle\", \"wb\") as f:\n",
    "    pickle.dump((words, labels, training, output), f)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])#Se utiliza red neuronal para buscar los tag con más probabilidad de coincidir\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)#Se utilizan 3 capas \n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "model.save(\"model.tflearn\")\n",
    "\n",
    "\n",
    "\n",
    "def bag_of_words(s, words):#Función de la bolsa de palabras donde se limpia y se guardan en booleano\n",
    "    s = s.lower()\n",
    "    s = re.sub('[^a-zA-ZáéíóúÁÉÍÓÚñÑüÜ]', ' ', s)  # Se reemplaza por espacio cualquier caracter que no sea letras en español\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "    s_words = lemmatize_sentence(s)\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "\n",
    "    print(f\"Bag of words for '{s}': {bag}\")  # Regresa un array con la bolsa de palabras con 0 y 1s\n",
    "    return np.array(bag)\n",
    "\n",
    "def chatbot_response(msg):\n",
    "    bow = bag_of_words(msg, words)\n",
    "    results = model.predict([bow])\n",
    "    print(f\"Model prediction for '{msg}': {results}\")  # En base a la bolsa de palabras se realiza una predicción con el valor máximo del array\n",
    "    results_index = np.argmax(results)\n",
    "    tag = labels[results_index]\n",
    "\n",
    "    for tg in data['intents']:\n",
    "        if tg['tag'] == tag:\n",
    "            responses = tg['responses']\n",
    "            return random.choice(responses)#En base a la selección máxima de la predicción, se escoge un random choice del tag\n",
    "\n",
    "    return \"Lo siento, no entiendo lo que quieres decir.\"\n",
    "\n",
    "\n",
    "base = Tk()  \n",
    "base.title(\"Chatbot\")  \n",
    "base.geometry(\"400x500\")  \n",
    "\n",
    "\n",
    "ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=(\"Arial\", 12), wrap=WORD)\n",
    "ChatLog.config(foreground=\"black\")\n",
    "ChatLog.insert(END, \"SALUDOS BIENVENIDO\\n\\n\") \n",
    "ChatLog.place(x=6, y=6, height=386, width=370) \n",
    "\n",
    "\n",
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
    "ChatLog['yscrollcommand'] = scrollbar.set\n",
    "scrollbar.place(x=376, y=6, height=386)\n",
    "\n",
    "\n",
    "ChatLog.config(state=DISABLED)\n",
    "\n",
    "\n",
    "EntryBox = Text(base, bd=0, bg=\"white\", width=\"29\", height=\"5\", font=(\"Arial\", 12), wrap=WORD)\n",
    "EntryBox.place(x=6, y=401, height=90, width=265)\n",
    "\n",
    "# Función para enviar un mensaje (se llama cuando se presiona Enter o se hace clic en el botón 'Send')\n",
    "def send(event=None):\n",
    "    msg = EntryBox.get(\"1.0\", 'end-1c').strip()  # Obtener el mensaje escrito por el usuario\n",
    "    EntryBox.delete(\"0.0\", END)  # Limpiar el cuadro de entrada después de enviar el mensaje\n",
    "\n",
    "    if msg != '':\n",
    "        ChatLog.config(state=NORMAL)  # Permitir la escritura en el área de texto\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')  # Mostrar el mensaje del usuario en el chat\n",
    "        ChatLog.config(foreground=\"black\")\n",
    "\n",
    "        # Obtener la respuesta del chatbot\n",
    "        res = chatbot_response(msg)\n",
    "        ChatLog.insert(END, \"ChatBOT: \" + res + '\\n\\n')  # Mostrar la respuesta del chatbot en el chat\n",
    "        ChatLog.config(state=DISABLED)  # Bloquear el área de texto nuevamente\n",
    "        ChatLog.yview(END)  # Desplazar hacia abajo para mostrar la respuesta más reciente\n",
    "\n",
    "# Botón para enviar mensajes\n",
    "SendButton = Button(base, font=(\"Verdana\", 12, 'bold'), text=\"Send\", width=\"9\",\n",
    "                   height=5, bd=0, bg=\"blue\", activebackground=\"gold\",\n",
    "                   fg='#ffffff', command=send)\n",
    "SendButton.place(x=282, y=401, height=90)\n",
    "\n",
    "# Vincular la tecla Enter para enviar mensajes\n",
    "base.bind('<Return>', send)\n",
    "\n",
    "# Iniciar el bucle principal de la interfaz gráfica\n",
    "base.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f066f7-f6e0-45da-bdb0-de5ea30c6306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d74bae-c923-41eb-8255-b13a19a9a1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
